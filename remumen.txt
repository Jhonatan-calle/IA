----TEO 1 GENETICOS

  Genotipo / Cromosoma 
    El el individuo de una población, un cromosoma puede expresarse como una cadena binaria, donde cada bit representa un gen.

  Poblacion: 
    cojunto de individuos (cromosomas)

  Aleleo:
    Un alelo es el valor específico que toma un gen.

  Metodos de selecion mas comunes
    -selecion por ruleta (FPS): cada individuo tiene una probabilidad de ser elegido proporcional a su aptitud, como si ocupara una porción de una ruleta cuyo tamaño depende de su valor de aptitud.
    -muestreo universal estocástico (SUS): se hace un solo giro de la ruleta y se seleccionan varios individuos a la vez usando puntos de selección equidistantes.
    -Escalado de aptitud: transforma los valores originales de aptitud mediante una función lineal fitness escalada = a * tness + b para ajustarlos a un rango deseado.
    -En la selección por torneo, se eligen al azar dos o más individuos de la población, y el que tenga la mayor aptitud es el que resulta seleccionado.

  Metodos de crossover mas usados 
    -En la combinación de un punto, se intercambian los genes a la derecha de un punto seleccionado al azar entre dos padres para crear dos descendientes con información genética combinada.
    -En la combinación de dos o más (k) puntos, se intercambian los genes situados entre dos o más puntos aleatorios seleccionados en los cromosomas de ambos padres.
    -En la combinación uniforme, cada gen del descendiente se elige de forma independiente, seleccionando al azar uno de los padres. Cuando la probabilidad es del 50%, ambos padres tienen la misma posibilidad de aportar cada gen.

  Algoritmo genético multiobjetivo (MOGA)
    es una extensión de los algoritmos genéticos tradicionales diseñada para optimizar varias funciones objetivo simultáneamente, que suelen estar en conflicto entre sí. Ejemplo típico: minimizar el costo y maximizar la calidad de un producto.

  Una solución A domina a otra solución B si:
    A es mejor o igual que B en todos los objetivos. A es estrictamente mejor que B en al menos un objetivo. Si ninguna de las dos domina a la otra, se dice que son no dominadas.

  Frente de Pareto:
    es el conjunto de soluciones no dominadas en el espacio de búsqueda. En la práctica, el objetivo de un MOGA es aproximar este frente para ofrecer al decisor un conjunto de soluciones con diferentes compensaciones.

  Algoritmo Non-dominated Sorting Genetic II (NSGA-2)
    El NSGA-II busca optimizar varios objetivos a la vez Se ordenan los individuos en niveles de dominancia:
      Frente 1: individuos no dominados por ningún otro (óptimos de Pareto actuales).
      Frente 2: dominados solo por los del Frente 1.
      Frente 3, y así sucesivamente.
    Dentro de cada frente, se mide la densidad local de soluciones vecinas. Sirve para mantener diversidad: se prefieren soluciones más aisladas (no amontonadas).


----TEO 2 REGRECION

  Distintos tipos de aprendizaje automático:
    Aprendizaje supervisado:
    El algoritmo recibe un conjunto de entrenamiento con las respuestas correctas y aprende a generalizar para responder correctamente a nuevas entradas.

    Aprendizaje no supervisado:
      No se proporcionan respuestas correctas. El algoritmo busca similitudes entre los datos para agruparlos.

    Aprendizaje por refuerzo (reinforcing):
      El algoritmo sabe si su respuesta fue correcta o no, pero no cómo mejorarla. Aprende explorando distintas opciones.

    Aprendizaje evolutivo:
      La evolución biológica puede interpretarse como un proceso de aprendizaje (aptitud de adaptación). Podemos modelar este proceso en una computadora usando el concepto de aptitud, que representa una puntuación que indica qué tan buena es una solución actual

  Problemas de clasificación:
    La salida del algoritmo es un valor tomado de un conjunto de finito de valores
 
  Problemas de predicción (regresión):
    La salida es un número entero o real

  Subajuste (Underfitting):
    Modelo es demasiado simple para captar los patrones de los datos.

  Sobreajuste (Overfitting):
    cuando el modelo aprende excesivamente de los datos de entrenamiento, incluyendo el ruido o las particularidades específicas, y por eso no generaliza bien a nuevos dato

  Medicion de calidad: 
    en problemas de clasificación se utilizan métricas como la precisión (accuracy), la sensibilidad (recall) o F1-Score que tiene en cuenta ambas anteriores. 
    En cambio, en problemas de regresión (predicción), se aplican métricas como el error absoluto medio (MAE) o el error cuadrático medio (MSE), que indican qué tan lejos están las predicciones de los valores reales

  Validación cruzada (cross-validation):
    Tecnica de particion de datos durante el desarrollo para cuando se dispone de pocos datos o para fortalecer la evaluación. La variante más simple (k-fold cross-validation), propone dividir los datos en k subconjuntos (folds). Se entrena el modelo k veces utilizando k – 1 folds para entrenamiento y el restante para prueba. Al final, se promedian los resultados.

  Costo computacioneas Regresion linean generalizado  = o(nm**2 + m**3) donde n son instancias y m caracteristicas lo cual lo vuelve no opcion no viable en un modelo mediano 

  Una alternativa es usar el gradiente de la funcion de costo y ir buscando el minimo iterativamente. Al no ser necesario calucalr la inversa de la matriz se reduce mucho la complejidad. pero esta solucion da una solucion aproximada que depende del learning rate y la de la cantidad de iteraciones que definamos

  Regresion polinomial: 
    La idea para poder ajustar modelos polinomiales es agregar más datos (características) con el valor de las características originales elevados al polinomio correspondiente. Luego buscamos, mediante la técnica de regresión lineal el modelo que mejor ajuste estos datos.

  Curvas de aprendizaje:
    Una manera de evaluar la calidad de nuestra función hipótesis (modelo aprendido) es mediante la denominadas curvas de aprendizaje. Estas curvas representan gráficamente el error mínimo cuadrado (RMSE) contrastándolo entre el conjunto de datos de entrenamiento y el de validación.

  Sesgo (Bias): 
    Esta parte del error de generalización se debe a suposiciones incorrectas, como asumir que los datos son lineales cuando en realidad son cuadráticos. Un modelo con alto sesgo probablemente presentará underfitting en los datos de entrenamiento.

  Varianza (Variance): 
    Esta parte se debe a la excesiva sensibilidad del modelo ante pequeñas variaciones en los datos de entrenamiento. Un modelo con muchos grados de libertad seguramente tendrá alta varianza y, por lo tanto, overfitting.

  Error irreducible (Irreducible error):
    Esta parte se debe al ruido inherente de los datos. La única manera de reducir este error es sanitizar los datos (por ejemplo, eliminando valores atípicos).

  En general, aumentar la complejidad de un modelo suele incrementar su varianza y reducir su sesgo. Reducir la complejidad tiende a aumentar el sesgo y disminuir la varianza.

  Regularizacion
    Una buena manera de reducir el overfitting es mediante la regularización del modelo, es decir,  imponerle restricciones. Una forma sencilla de regularizar un modelo polinómico es reducir el número de grados del polinomio. La regularización se logra normalmente restringiendo los pesos del modelo:

    Ridge Regression: 
      Penaliza la suma de los cuadrados de los pesos del modelo. Fórmula de penalización. Ridge suele ser una buena opción por defecto

    Lasso Regression (Least Absolute Shrinkage and Selection Operator) : 
      Penaliza la suma de los valores absolutos de los pesos. Si se sospecha que pocas características son útiles, se prefiere Lasso o Elastic Net, ya que reducen los pesos de las características innecesarias a cero.

    Elastic Net Regression:
      Técnica de regularización que combina Ridge y Lasso. suele ser preferible respecto Lasso. Lasso NO suele funcionar bien cuando el número de características es mayor al número de instancias de entrenamiento, o cuando hay una correlación fuerte entre algunas características

  Finalización Temprana (Early Stopping):
    Cuando el entrenamiento es iterativo (Estocástico por Gradiente), el modelo que da mejores resultados en el conjunto de validación puede aparecer en iteraciones intermedias durante el entrenamiento. Esto se debe a que en las últimas iteraciones se suele hacer overfitting sobre el conjunto de entrenamiento. Early stopping consiste en guardar el modelo con mejores resultados contrastados con el conjunto de datos de validación.


------TEO 3 Datos

  Proceso de modelado y utilizacion 
    1. Problem Definition: 
      Definir claramente qué problema se quiere resolver, los objetivos y las métricas a utilizar.
    2. Data Collection: 
      Obtener los datos necesarios desde las fuentes disponibles.
    3. Data Cleaning and Preprocessing: 
      Corregir errores, manejar valores faltantes, normalizar y transformar los datos para que el modelo los pueda usar.
    4. Exploratory Data Analysis: 
      Analizar visual y estadísticamente los datos para entender patrones,tendencias y posibles problemas.
    5. Feature Engineering and Selection: 
      Crear nuevas características relevantes y seleccionar las más útiles para mejorar el rendimiento del modelo.
    6. Model Selection: 
      Elegir el tipo de modelo que probablemente funcione mejor según el problema y los datos.
    7. Model Training: 
      Entrenar el modelo con los datos de entrenamiento para que aprenda patrones.
    8. Model Evaluation and Tuning: 
      Evaluar el rendimiento en datos de prueba y ajustar hiperparámetrospara optimizarlo.
    9. Model Deployment and Maintenance: 
      Poner el modelo en producción para que empiece a usarse.


------TEO 4 clasificación

  La clasificación es una tarea de aprendizaje supervisado en la que un modelo aprende a asignar una etiqueta o categoría a una entrada, basándose en ejemplos previos con etiquetas conocidas. Estas etiquetas o categorías deben ser discretas y acotadas, sino estaríamos en un problema de regresión.

  Diferentes tipos de clasificación
    Clasificación Binaria: 
      cuando la cantidad de características o etiquetas son dos (por ejemplo, detección de spam en el correo) ?
    Clasificación Multi-clase: 
      cuando la cantidad de características o etiquetas son más de dos (por ejemplo, detección de frutas)
    Clasificación Multi-etiqueta: 
      cuando los individuos pueden tener más de una etiqueta o característica (por ejemplo, características de una foto: (sepia/color, día/noche, ...)

  Resultado de las predicciones:
    True positives TF (Positivos Verdaderos): 
      casos en los cuales la clase C predicha coincide con la real
    False positives FP (Positivos Falsos): 
      casos en los cuales la clase C predicha no coincide con la clase del individuo correspondiente
    True negatives TN(Negativos Verdaderos): 
      casos en los cuales la clase predicha no es C, y efectivamente los individuos correspondientes no son de clase C
    False negatives FN(Negativos Falsos): 
      casos en los cuales la clase predicha por el clasificador no es C, pero los individuos correspondientes corresponden a la clase C.

  Exactitud (Accuracy):
    (correstos: falsos y verdaderos) / todos
    Es una métrica muy simple ¿ cuántos clasifica correctamente ?

  Precision (Precisión): 
    De todos los casos que el modelo predijo como positivos, ¿cuántos realmente eran positivos? (con abilidad)

  Recall (Exhaustividad):  
    De todos los casos que realmente eran positivos, ¿cuántos detectó el modelo correctamente? (detección)

  F1-Score: 
    (presicion*recall) / (presicion+recall)
    Sirve cuando queremos balancear falsos positivos y falsos negativos.

  clasificacion lineal:
    Los casos más simples de clasi cación es la clasi cación lineal. Donde buscamos aprender una función lineal que nos divida el conjunto de elementos según la clase a la que pertenece. A esta función se la denomina decision boundary (frontera de decisión) o separador lineal.

  Perceptron:
    Calcula una suma ponderada por pesos, y aplica una función de activación al resultado, Si resultado es superior a un umbral, retorna 1, sino 0

    El bias en el perceptrón es un parámetro adicional que permite desplazar la frontera de decisión y mejorar la capacidad de aprendizaje del modelo.

  Logistic Regression:
    en vez de calcular si pertenece o no a una clase (discreto) es calcular la probabilidad de que pertenezca. Para ello utilizamos un función Sigmoide (en forma de “S”).

    Log Loss (pérdida logarítmica): 
      Funcion de costo muy utilizada en logistic regression para el entrenamiento. Ésta mide cuán bien se ajustan la probabilidad predicha respecto de la clase real (valor correcto). La pérdida logarítmica se calcula como el promedio negativo del logaritmo de las probabilidades predichas, teniendo en cuenta tanto las predicciones correctas como las incorrectas.
      Una ventaja de Logistic Regression es que la función de decisión es diferenciable, con lo cual podemos aplicar la técnica del descenso del gradiente para encontrar los parámetros que minimizan el error de predicción.

    Multi-clase:
      Enfoque One-vs-the-Rest (OvR):
        Entrenar un clasificador por cada clase y seleccionamos como clase resultante aquella con valor más alto (mayor probabilidad)

      Enfoque One-vs-One (OvO):
        Entrenar un clasificador para distinguir cada par de clase. Se genera y entrenan muchos clasificadores N * (N − 1)/2 para N clases y se retorna como resultado de la predicción la clase que gana más "comparaciones" (más veces vs. las restantes).

      regresión softmax (softmax regression): 
        O regresión logística multinomial (multinomial logistic regression) es una tecnica para manejar múltiples clases directamente, sin la necesidad de entrenar y combinar varios clasificadores binarios
        La idea es que cuando llega una instancia x a ser clasificada. El modelo calcula un score sk(x) para cada clase k. Este score es parecido a la regresión logística tradicional, es un valor linea. Luego, aplica la función softmax (también llamada exponencial normalizada) para convertir esos scores en probabilidades.
        La idea es que todas las probabilidades quedan entre 0 y 1, y suman exactamente 1. La clase a predecir será la que tenga la probabilidad más alta.

        función de costo de entropía cruzada (cross-entropy loss):
          funcion de costo de entranamiento en modelo softmax el cual debe asignar alta probabilidad a la clase correcta y baja probabilidad a las Además. Como la función de costo de entropía cruzada (cross-entropy loss) es diferenciable, para realizar el entrenamiento podemos aplicar la técnica del descenso del gradiente para ir ajustando los pesos asociados a cada clase.


------TEO 5 clasificación no parametrica
|
  En machine learning, un modelo no paramétrico es aquel que no asume una forma funcional para los datos (como una recta o un polinomio). Además, en general, la complejidad del modelo crece con la cantidad de datos.
  
  k-Nearest Neighbors (k-NN): 
    Predice según los vecinos más cercanos en el espacio de características. almacena los datos de entrenamiento para buscar los k vecinos más cercanos al nuevo punto de entrada para predecir su valor.
    no es necesario entrenamiento alguno. Si se deben tener en cuenta varios hiperparámetros:
    • Cuántos vecinos se van a tener en cuenta, usualmente una cantidad impar: algunas heuritiscas son elijir k como la raiz del nro de datos de entranamiento pero la mejor opcion segun la teoria es utilizar cross-validation para encontrar el k que maximiza la presicion
    • Cómo medimos la distancia de proximidad
    • Cómo determinamos el valor a predecir
  
  cuando se estan compararndo valores cuyas escalas son diferentes (por ejemplo edad y kilomentos) es combinente escalar las maginitudes para que todos tengan como media 0 y desviacion estardar 1

  Para determinar el valor a predecir (clase) el método más utilizado es el de votación mayoritaria entre las clases de los vecinos.

  Maquinas de soporte vectorial (SVM):
    La idea de SVM es tratar de encontrar cuál es la mejor forma de partir (separar) clases de valores para poder clasificarlos

    SVM - Soft Margin:
      El soft margin permite que algunos puntos estén mal clasificados o dentro del margen, con el objetivo de obtener un modelo que generalice mejor. Esto se logra introduciendo slack variables, que miden cuántos puntos “violan” la separación correcta.
    
    Ventajas
      • Buen rendimiento en alta dimensión: Funciona muy bien con datos de muchas variables,por ejemplo imágenes.
      • Manejo de relaciones no lineales: Gracias a los kernels (RBF, polinómico).
      • Robustez frente a outliers: El soft margin permite ignorar ciertos puntos atípicos.
      • Clasificación binaria y multiclase: Útil tanto para dos clases como para múltiples clases.

    Desventajas
      • Entrenamiento lento: Muy costoso en datasets grandes.
      • Di cultad en la selección de parámetros: Elegir kernel y ajustar hiperparámetros suele ser complejo.
      • Sensibilidad al ruido: Pierde rendimiento con datos ruidosos o clases solapadas.
      • Poca interpretabilidad: Difícil de entender en espacios de alta dimensión.
      • Necesidad de escalado: Requiere normalizar/estandarizar los datos para un buen desempeño.

  Árboles de decisión (DT):
    Su objetivo es construir un modelo que prediga el valor de una variable objetivo mediante reglas de decisión simples derivadas de las características de los datos.

    ¿ Cómo podemos construir (aprender) un DT ?... de una forma optimal. La construcción del mejor DT (más eficiente) es un problema NP completo.

    Índice Gini (para clasificación): 
      El coe ciente gini mide la “pureza” de un nodo. Un nodo se dice “puro” (gini=0)si contiene todas muestras del mismo tipo

    Pruning:
      La poda es una técnica para reducir su complejidad y evitar el overfitting. Un árbol muy profundo puede ajustarse demasiado a los datos de entrenamiento capturando ruido en lugar de patrones generales. Pruning consiste en eliminar ramas o nodos que aportan poca mejora en la predicción, logrando así un modelo más simple, generalizable y eficiente.

      Pre-pruning (poda temprana): 
        se detiene el crecimiento del árbol antes de que alcance su máxima profundidad, aplicando criterios como un número mínimo de muestras por nodo o una ganancia mínima de información.

      Post-pruning (poda posterior): 
        primero se entrena un árbol grande y luego se recortan ramas evaluando el impacto en un conjunto de validación o mediante métricas como error o complejidad.


------TEO 6 Ensambles 
  Un ensemble es una técnica en machine learning supervisado donde se combinan múltiples modelos para formar un modelo más robusto

  Bagging (Bootstrap Aggregating): 
    Entrena varios modelos en paralelo sobre subconjuntos aleatorios de los datos. Luego combina sus predicciones (votación en clasificación, promedio en regresión). Ejemplo: Random Forests (construye muchos árboles de decisión).

  Bagging -random forest 
    Random Forest es un algoritmo de ensemble basado en bagging que combina múltiples árboles de decisión para mejorar la precisión y la capacidad de generalización. Fue propuesto por Leo Breiman en 2001 como una extensión del bagging, con la innovación de agregar aleatoriedad en la selección de atributos en cada división del árbol.
    
  Boosting:  
    Boosting es una técnica que combina múltiples modelos débiles (weak learners) para formar un modelo fuerte (strong learner). La idea es entrenar de manera secuencial a varios modelos, donde cada modelo nuevo se enfoca en corregir los errores cometidos por los anteriores. En lugar de entrenar todos los modelos en paralelo (como en bagging), los modelos se construyen uno tras otro ajustando la importancia de las instancias según la di cultad de clasificarlas.

  Stacking (Stacked Generalization): 
    Combina diferentes tipos de modelos (heterogéneos). Usa un meta-modelo que aprende a integrar sus predicciones. Ejemplo: usar k-NN + SVM + árbol de decisión, y luego una regresión logística para combinar. A diferencia de Bagging o Boosting, que combinan modelos de la misma familia.

  Voting: 
    Se seleccionan diferentes tipos de modelos con buen desempeño. Se entrenan cada uno de los correspondientes modelos. Dada una consulta, se realiza la misma en cada modelo entrenado. Dadas las respuestas se somete a un proceso de votación. Para problemas de clasificación se utiliza mayority, para uno de regresión, generalmente el promedio de los resultados. También se puede utilizar una soft voting utilizando probabilidades


------TEO 7 redes neuronales

  Perceptron con respuesta probabilística:
    Con el mismo objetivo que para clasificación, en lugar de utilizar una decisión discreta (>0,<=0), utilizamos una función que nos proyecte la salida en una probabilidad en 0 y 1.

  Combinando varios perceptrones (neuronas) podemos crear una Red Neuronal

  red neuronal artificial(ANN):
    es un modelo computacional compuesto por unidades llamadas neuronas arti ciales, organizadas en capas (entrada, ocultas y salida), que están conectadas entre sí mediante pesos.

  backprogration 
    metodo de entranmiento de una red neuroanl. mediante el gradiente de la funcion de costo 


------TEO 8 redes convolucionales 
  
  Una Red Neuronal Convolucional (CNN) es un tipo de red neuronal diseñada para procesar datos con estructura espacial, como imágenes.

  convolucion:
    Una convolución es una operación que combina dos funciones f y g para producir una tercera función que expresa cómo una de ellas modifica o “suaviza” a la otra. Si asociamos a la función f representando el dato de entrada y la segunda g como el patrón a detectar, la convolución modifica la entrada proyectando el patrón sobre ella

  En dos dimensiones se denormina filtro o kernel a la funcion g que es aplicada a f y el parametro strike o salto indica cuánto se desplaza el kernel en la entrada durante la convolución

  Si necesitamos atención en los bordes podemos rellenar los bordes (padding)

  pooling:
    Las capas de pooling tienen como objetivo reducir el tamaño de los mapas de características conservando la información más importante. Para ello resume regiones (por ejemplo, de 2×2) tomando el valor máximo (max-pooling) o el promedio (average pooling). Este proceso disminuye la cantidad de parámetros, hace el modelo más eficiente y genera invariancia a pequeñas traslaciones o deformaciones.

  Data Augmentation (aumento de datos):
    tecnica a la que se puede recurrir para mejorar la generalizacion del modelo cuando la cantidad y calidad de los datos no es suficiente respecto a diversidad. Data Augmentation genera nuevas imágenes arti ciales aplicando transformaciones aleatorias que no cambian la clase del objeto

  Ventajas CNN :
    Sparse Interactions (Interacciones dispersas o locales):
      En una convolucional, cada neurona de la salida se conecta solo con una pequeña región local de la entrada, el receptive eld (campo receptivo). Esto genera interacciones dispersas, lo que reduce drásticamente los parámetros y el costo computacional. Esta “dispersión” permite que la red se concentre en patrones locales (bordes, texturas, esquinas) antes de combinarlos en niveles más altos para detectar formas globales.

    Parameter Sharing (Compartición de parámetros) :
      En una ANN tradicional, cada conexión tiene su propio peso wij. En cambio en una convolucional, el mismo conjunto de pesos (el filtro o kernel) se aplica a lo largo de toda la entrada. Los pesos se comparten en todas las posiciones (i, j), lo que significa que el número de parámetros no depende del tamaño de la entrada. La red aprende un ltro universal que detecta la misma característica (por ejemplo, un borde) en cualquier lugar de dato de entrada. Esto permite que la red sea invariante a traslaciones: un patrón desplazado produce la misma respuesta

    Equivariance to Translation and Variable-Sized Inputs (Equivarianza e invariancia):
      Una operación es equivariante si un cambio en la entrada produce un cambio correspondiente en la salida. En una convolución: f(T(x)) = T(f(x)) donde T representa una traslación (desplazamiento). Esto significa que si desplazamos la imagen de entrada, el mapa de características se desplaza de la misma forma.
      Además, se puede trabajar con entradas de tamaño variable, porque el filtro convolucional opera localmente y no depende de la dimensión total de la entrada. Las capas de pooling y global average pooling permiten reducir las dimensiones antes de la capa de salida, independientemente del tamaño de entrada original.

